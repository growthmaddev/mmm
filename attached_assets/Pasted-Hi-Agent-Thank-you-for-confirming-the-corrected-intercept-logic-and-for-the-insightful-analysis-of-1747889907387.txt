Hi Agent,

Thank you for confirming the corrected intercept logic and for the insightful analysis of adstock/saturation parameter extraction for model 26. Your findings confirm that the reliance on default parameters for these transformations is likely a major contributor to the current low R-squared and problematic baseline.

We will now act on your excellent and comprehensive suggestions for "Diagnostic Steps and Potential Changes for `train_mmm.py`."

Please proceed with the following modifications to `train_mmm.py`:

**Task 1: Implement Data-Driven Adstock & Saturation Parameters**
    a.  Implement your proposal for **"Adaptive Saturation Parameters."**
        i.  Ensure **Saturation `x0` (Midpoint)** is set based on a data-driven characteristic (e.g., median spend) for each specific channel.
        ii. Implement your suggestion to adjust **Saturation `k` (Steepness)** based on data scale (e.g., inversely to spend level like `k = 0.0005 / (x0 / 1000 if x0 > 0 else 1)`, or a similar adaptive approach you deem best).
        iii. For **Saturation `L` (Ceiling)**, you can keep it at 1.0 if you're also implementing predictor/target scaling, or advise if it also needs to be adaptive.
    b.  For **Adstock `alpha` (Decay) & `l_max` (Max Lag)**:
        i.  These are currently hardcoded defaults. Investigate and implement a way to make these more data-driven or at least more configurable per channel. If PyMC-Marketing allows these to be learned (i.e., set as priors in the model rather than fixed values) without excessive custom programming, that would be ideal.
        ii. If direct learning is too complex for this iteration, implement a method to set more informed, data-driven *initial values or bounds* for `alpha` and `l_max` per channel, rather than a single global default.
    c.  These adaptive parameters should be used when initializing the `MMM` object, likely via the `media_transforms` argument as you previously suggested.

**Task 2: Implement Key Data Preprocessing Options (as Configurable Steps)**
    a.  **Log-Transform Target Variable:** Implement your suggestion to add an option (e.g., controlled by the input `config` JSON) to log-transform the target variable `y` (e.g., using `y_transformed = np.log1p(y)`).
        * Ensure that if the target is transformed, predictions are appropriately back-transformed to the original scale before calculating metrics like RMSE against the original `y`, and for any sales figures reported in the JSON output.
    b.  **Scale Predictor Variables:** Implement your suggestion for an option (e.g., controlled by the input `config` JSON) to standardize/scale the predictor variables (channel spends and any control variables passed in `X`) using, for example, `sklearn.preprocessing.StandardScaler`.

**Task 3: Implement Data Diagnostic Checks (High Priority)**
    a.  Implement the comprehensive `run_diagnostics` function you proposed (checking data volume, spend-sales correlations, collinearity via PCA, target variable stationarity via ADF test, target variable statistics, outlier detection).
    b.  Integrate the output of this function into a new top-level key (e.g., `"data_diagnostics_report"`) in the JSON results from `train_mmm.py`.
    c.  Ensure warnings and key findings from diagnostics are also printed to `stderr`.

**MCMC Settings:** For these development iterations, please revert to and use faster MCMC settings (e.g., `draws=200, tune=100, chains=2`) to allow for quicker testing of these structural changes. We will conduct specific tests with higher MCMC settings later once these enhancements are in place.

**Deliverables:**
1.  The updated `train_mmm.py` script incorporating all these changes.
2.  An example of the new `"data_diagnostics_report"` section from a test run.
3.  A summary explaining how adstock and saturation parameters are now being handled (i.e., how they are made more data-driven).
4.  Confirmation of how the log-transform for the target and scaling for predictors are implemented and made configurable.

These are significant enhancements. Take them step-by-step, and focus on robust implementation.